<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> The Bio-Science AI Hackathon | Alexander Aghili </title> <meta name="author" content="Alexander Aghili"> <meta name="description" content=""> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/prof_pic.jpg?6c6f9940b9db3e43232845430e752c5c"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="/blog/2024/QBI-Hackthon/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Alexander Aghili </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">The Bio-Science AI Hackathon</h1> <p class="post-meta"> Created in August 06, 2024 </p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/tag/ai"> <i class="fa-solid fa-hashtag fa-sm"></i> AI</a>   <a href="/blog/tag/biotechnology"> <i class="fa-solid fa-hashtag fa-sm"></i> Biotechnology</a>   <a href="/blog/tag/bioscience"> <i class="fa-solid fa-hashtag fa-sm"></i> Bioscience</a>   <a href="/blog/tag/hackathon"> <i class="fa-solid fa-hashtag fa-sm"></i> Hackathon</a>   ·   <a href="/blog/category/reflections"> <i class="fa-solid fa-tag fa-sm"></i> Reflections</a>   <a href="/blog/category/software"> <i class="fa-solid fa-tag fa-sm"></i> Software</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <h2 id="introduction">Introduction</h2> <p>Recently, I had the chance to join the QBI bio-hackathon at UCSF. This year’s focus was on using machine learning and artificial intelligence to advance medicine. There were many incredible projects, like breast cancer detection using imaging and protein visualization. I was excited about contributing my computing skills to medical problems. Technology advancements that improve medicine can significantly enhance people’s lives.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/QBIHackathon/Hackathon-480.webp 480w,/assets/img/QBIHackathon/Hackathon-800.webp 800w,/assets/img/QBIHackathon/Hackathon-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/QBIHackathon/Hackathon.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>Initially, I didn’t have a team. Fortunately, we were given the opportunity to pitch ideas and join existing teams. One pitch that caught my attention was from a Ph.D. researcher at UCSF, who was grappling with a challenging issue related to scientific data.</p> <p>Advancements in Artificial Intelligence and Machine Learning in medicine depend on high-quality data for successful results. For example, Alpha Fold, arguably the most successful AI tool in biology to date, relied on the Protein Data Bank, a manually curated database of biomolecular structures for training. This data bank was assembled by researchers throughout the field collaborating and contributing in this centralized repository. Thus, for further predictive analysis capabilites, we need more data.</p> <p>However, getting the correct data and metadata is difficult, as researchers do not like spending time on data formatting and deposition. Oftentimes, they may not be aware or simply forget to input the data into the data bank whenever they have discovered a new structure. Thus, to solve this issue, we want to scan through recently published papers that report structures of biomolecules so we can reach out to authors and bring their data into PDB.</p> <p>The researcher leading this hackathon project, over the previous summer, had interns manually go through papers and fill out a spreadsheet with information about the article. Such information includes which methods were used to image the protein or if multiple methods were used. The team could then reach out to the researchers and encourage/collaborate with them to input their data into the protein data bank. The given task, for our hackathon, was to try and automate this pipeline. With recent advancements using LLMs, we figured it’d be possible to do the entire pipeline.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/QBIHackathon/Data-Interns-480.webp 480w,/assets/img/QBIHackathon/Data-Interns-800.webp 800w,/assets/img/QBIHackathon/Data-Interns-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/QBIHackathon/Data-Interns.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h2 id="project-description">Project Description</h2> <p>Here were the specific goals we were tasked with:</p> <ol> <li>A Python script that accepts a paper (plain text or pdf) and performs annotation with a set of predefined questions.</li> <li>A Python script, that pulls updates from a set of bio/medRxiv subtopics, calls script 1, puts results into a GoogleSheet and triggers email notification.</li> <li>Purely open source/free software implementation using open/free LLMs or other approaches.</li> </ol> <p>Since the relevant papers are available through bioRxiv and medRxiv, we used those as the data source. They conveniently have an API to access journal data as well.</p> <p>To get the prototype working, we decided to use the GPT 4.0 API. While this does break the 3rd goal, the LLM is easily replaceable by an open source alternative. The basic pipeline we created is as follows. We get the papers from the bioRxiv API and extract the metadata from the content. We turn the content into vector embeddings using OpenAI’s embeddings and store the embeddings in the Lantern Vector+postgres database, who was sponsoring the event. This helped us store the data about the papers for the long term and ask additional questions if necessary. We then used FAISS context retrieval to retrieve the context based on a given input using cosine similarity. We use GPT 4.0 to annotate the retrieved data and use Google Sheets and Mail APIs to save the data and notify stakeholders. We use AWS to host the architecture through an EC2 instance. We used langchain to help with LLM utilities.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/QBIHackathon/AWS-pipeline-480.webp 480w,/assets/img/QBIHackathon/AWS-pipeline-800.webp 800w,/assets/img/QBIHackathon/AWS-pipeline-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/QBIHackathon/AWS-pipeline.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h2 id="implementation">Implementation</h2> <p>I will now go into depth for each part of the architecture with code. Starting with the bioRxiv scraper, in scraper.py: We utilized a python library that provided the <a href="https://api.biorxiv.org/" rel="external nofollow noopener" target="_blank">bioRxiv API</a> functionality for us called <a href="https://pypi.org/project/paperscraper/" rel="external nofollow noopener" target="_blank">paperscraper</a>.</p> <p>This allowed us to use the function bioXriv to download pdf versions of papers published between a certain date.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="sh">"""</span><span class="s">
Scrapes papers from bioRxiv between the specified dates and saves the metadata in a JSON file.

:param start: Start date for the scraping (format: </span><span class="sh">"</span><span class="s">YYYY-MM-DD</span><span class="sh">"</span><span class="s">).
:param end: End date for the scraping (format: </span><span class="sh">"</span><span class="s">YYYY-MM-DD</span><span class="sh">"</span><span class="s">).
:param out_file: Output file to save the metadata in JSON Lines format.
:return: None
</span><span class="sh">"""</span>
<span class="k">def</span> <span class="nf">scrapeBiorxiv</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">out_file</span><span class="p">):</span>
    <span class="n">filepath</span> <span class="o">=</span> <span class="n">out_file</span>
    <span class="nf">biorxiv</span><span class="p">(</span><span class="n">begin_date</span><span class="o">=</span><span class="n">start</span><span class="p">,</span> <span class="n">end_date</span><span class="o">=</span><span class="n">end</span><span class="p">,</span> <span class="n">save_path</span><span class="o">=</span><span class="n">out_file</span><span class="p">)</span>
    <span class="nf">retreiveTextFromPdf</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span>

</code></pre></div></div> <p>After downloading all the papers, we scrape them using the retreiveTextFromPdf function. For each unique article (identified by DOI stored in the SQL database), we extract the text from the pdf, and get vector embeddings using the get_embeddings() function.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="sh">"""</span><span class="s">
Retrieves text from PDF files, extracts embeddings, and stores information in a custom database.

:param inp_file: Path to the input JSON file containing paper metadata.
:return: None
</span><span class="sh">"""</span>
<span class="k">def</span> <span class="nf">retreiveTextFromPdf</span><span class="p">(</span><span class="n">inp_file</span><span class="p">):</span>

    <span class="n">json</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_json</span><span class="p">(</span><span class="n">path_or_buf</span><span class="o">=</span><span class="n">inp_file</span><span class="p">,</span> <span class="n">lines</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">lantern</span> <span class="o">=</span> <span class="nc">Lantern</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">doi</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">json</span><span class="p">[</span><span class="sh">'</span><span class="s">doi</span><span class="sh">'</span><span class="p">]):</span>

        <span class="n">paper_data</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">doi</span><span class="sh">'</span><span class="p">:</span> <span class="n">doi</span><span class="p">}</span>
        <span class="n">doi</span> <span class="o">=</span> <span class="n">doi</span><span class="p">.</span><span class="nf">replace</span><span class="p">(</span><span class="sh">"</span><span class="s">/</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">-</span><span class="sh">"</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">lantern</span><span class="p">.</span><span class="nf">publicationExists</span><span class="p">(</span><span class="n">doi</span><span class="p">):</span>
            <span class="k">continue</span>

        <span class="n">pdf_dir</span> <span class="o">=</span> <span class="sh">'</span><span class="s">./papers/</span><span class="sh">'</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">exists</span><span class="p">(</span><span class="n">pdf_dir</span><span class="p">):</span>
            <span class="n">os</span><span class="p">.</span><span class="nf">mkdir</span><span class="p">(</span><span class="n">pdf_dir</span><span class="p">)</span>

        <span class="n">pdfsavefile</span> <span class="o">=</span> <span class="sh">'</span><span class="s">./papers/</span><span class="sh">'</span> <span class="o">+</span> <span class="n">doi</span> <span class="o">+</span> <span class="sh">'</span><span class="s">.pdf</span><span class="sh">'</span>
        <span class="nf">save_pdf</span><span class="p">(</span><span class="n">paper_data</span><span class="p">,</span> <span class="n">filepath</span><span class="o">=</span><span class="n">pdfsavefile</span><span class="p">)</span>

        <span class="c1"># creating a pdf reader object
</span>        <span class="n">reader</span> <span class="o">=</span> <span class="n">PyPDF2</span><span class="p">.</span><span class="nc">PdfReader</span><span class="p">(</span><span class="n">pdfsavefile</span><span class="p">)</span>
        <span class="n">save_txt_path</span> <span class="o">=</span> <span class="sh">'</span><span class="s">scrapped_txts/</span><span class="sh">'</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">exists</span><span class="p">(</span><span class="n">save_txt_path</span><span class="p">):</span>
            <span class="n">os</span><span class="p">.</span><span class="nf">mkdir</span><span class="p">(</span><span class="n">save_txt_path</span><span class="p">)</span>
        <span class="n">extract_text</span> <span class="o">=</span> <span class="sh">''</span>
        <span class="k">for</span> <span class="n">page</span> <span class="ow">in</span> <span class="n">reader</span><span class="p">.</span><span class="n">pages</span><span class="p">:</span>
            <span class="n">extract_text</span> <span class="o">+=</span> <span class="n">page</span><span class="p">.</span><span class="nf">extract_text</span><span class="p">()</span>

        <span class="n">txt_file</span> <span class="o">=</span> <span class="nf">str</span><span class="p">(</span><span class="sh">'</span><span class="s">{}.txt</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">doi</span><span class="p">))</span>
        <span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="n">save_txt_path</span> <span class="o">+</span> <span class="n">txt_file</span><span class="p">,</span> <span class="sh">'</span><span class="s">w</span><span class="sh">'</span><span class="p">)</span> <span class="k">as</span> <span class="nb">file</span><span class="p">:</span>
            <span class="nb">file</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="n">extract_text</span><span class="p">)</span>

        <span class="n">txt_embs</span><span class="p">,</span> <span class="n">emb</span> <span class="o">=</span> <span class="nf">get_embeddings</span><span class="p">(</span><span class="n">save_txt_path</span> <span class="o">+</span> <span class="n">txt_file</span><span class="p">)</span>
        <span class="bp">...</span>
</code></pre></div></div> <p>Get_embeddings will split the input text into chunks and create a vector embedding using OpenAI Embeddings for each chunk.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="sh">"""</span><span class="s">
Retrieves text embeddings from a given text file using OpenAI</span><span class="sh">'</span><span class="s">s language model.

:param fname: Path to the input text file.
:return: A tuple containing text embeddings and the OpenAIEmbeddings instance.
</span><span class="sh">"""</span>
<span class="k">def</span> <span class="nf">get_embeddings</span><span class="p">(</span><span class="n">fname</span><span class="p">):</span>
    <span class="n">loader</span> <span class="o">=</span> <span class="nc">TextLoader</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span>
    <span class="n">documents</span> <span class="o">=</span> <span class="n">loader</span><span class="p">.</span><span class="nf">load</span><span class="p">()</span>
    <span class="n">text_splitter</span> <span class="o">=</span> <span class="nc">CharacterTextSplitter</span><span class="p">(</span>
        <span class="n">separator</span><span class="o">=</span><span class="sh">"</span><span class="s">.</span><span class="sh">"</span><span class="p">,</span> <span class="n">chunk_size</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">chunk_overlap</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">docs</span> <span class="o">=</span> <span class="n">text_splitter</span><span class="p">.</span><span class="nf">split_documents</span><span class="p">(</span><span class="n">documents</span><span class="p">)</span>

    <span class="n">emb</span> <span class="o">=</span> <span class="nc">OpenAIEmbeddings</span><span class="p">()</span>
    <span class="n">input_texts</span> <span class="o">=</span> <span class="p">[</span><span class="n">d</span><span class="p">.</span><span class="n">page_content</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">docs</span><span class="p">]</span>

    <span class="n">input_embeddings</span> <span class="o">=</span> <span class="n">emb</span><span class="p">.</span><span class="nf">embed_documents</span><span class="p">(</span><span class="n">input_texts</span><span class="p">)</span>
    <span class="n">text_embeddings</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="nf">zip</span><span class="p">(</span><span class="n">input_texts</span><span class="p">,</span> <span class="n">input_embeddings</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">text_embeddings</span><span class="p">,</span> <span class="n">emb</span>

</code></pre></div></div> <p>To get an understanding of the next part, we have to understand the database structure. We decided to have to main tables with the following structures:</p> <ol> <li>The Publication Table - Holds publication metadata <ol> <li>DOI (Digital Object Identifier) - Universal Paper Identifier</li> <li>The title</li> <li>pmc link</li> <li>pubmed link</li> </ol> </li> <li>The Fragments Table <ol> <li>DOI (Foreign Key used to identify which paper fragment is from)</li> <li>Header</li> <li>Content</li> <li>Vector</li> </ol> </li> </ol> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="c1"># Class to represent a publication with attributes id, title, pmc, pubmed, and doi
</span><span class="k">class</span> <span class="nc">Publication</span><span class="p">:</span>
    <span class="nb">id</span> <span class="o">=</span> <span class="sh">""</span>
    <span class="n">title</span> <span class="o">=</span> <span class="sh">""</span>
    <span class="n">pmc</span> <span class="o">=</span> <span class="sh">""</span>
    <span class="n">pubmed</span> <span class="o">=</span> <span class="sh">""</span>
    <span class="n">doi</span> <span class="o">=</span> <span class="sh">""</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="nb">id</span><span class="p">,</span> <span class="n">title</span><span class="p">,</span> <span class="n">pmc</span><span class="p">,</span> <span class="n">pubmed</span><span class="p">,</span> <span class="n">doi</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="nb">id</span> <span class="o">=</span> <span class="nb">id</span>  <span class="c1"># (DOI) Unique identifier for the publication
</span>        <span class="n">self</span><span class="p">.</span><span class="n">title</span> <span class="o">=</span> <span class="n">title</span>  <span class="c1"># Title of the publication
</span>        <span class="n">self</span><span class="p">.</span><span class="n">pmc</span> <span class="o">=</span> <span class="n">pmc</span>  <span class="c1"># PubMed Central (PMC) Link
</span>        <span class="n">self</span><span class="p">.</span><span class="n">pubmed</span> <span class="o">=</span> <span class="n">pubmed</span>  <span class="c1"># PubMed Link
</span>        <span class="n">self</span><span class="p">.</span><span class="n">doi</span> <span class="o">=</span> <span class="n">doi</span>  <span class="c1"># Digital Object Identifier (DOI) Link for the publication
</span>

<span class="c1"># Class to represent a fragment of a publication with attributes id, header, content, and vector
</span><span class="k">class</span> <span class="nc">Fragment</span><span class="p">:</span>
    <span class="c1"># Class variables to store default values for attributes
</span>    <span class="nb">id</span> <span class="o">=</span> <span class="sh">""</span>
    <span class="n">header</span> <span class="o">=</span> <span class="sh">""</span>
    <span class="n">content</span> <span class="o">=</span> <span class="sh">""</span>
    <span class="n">vector</span> <span class="o">=</span> <span class="sh">""</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="nb">id</span><span class="p">,</span> <span class="n">header</span><span class="p">,</span> <span class="n">content</span><span class="p">,</span> <span class="n">vector</span><span class="p">):</span>
        <span class="c1"># Constructor to initialize the attributes of the Fragment object
</span>
        <span class="c1"># Set the attributes of the object with the values provided during instantiation
</span>        <span class="n">self</span><span class="p">.</span><span class="nb">id</span> <span class="o">=</span> <span class="nb">id</span>  <span class="c1"># (DOI) Unique identifier for the fragment
</span>        <span class="n">self</span><span class="p">.</span><span class="n">header</span> <span class="o">=</span> <span class="n">header</span>  <span class="c1"># Header or title of the fragment
</span>        <span class="n">self</span><span class="p">.</span><span class="n">content</span> <span class="o">=</span> <span class="n">content</span>  <span class="c1"># Content or text of the fragment
</span>        <span class="n">self</span><span class="p">.</span><span class="n">vector</span> <span class="o">=</span> <span class="n">vector</span>  <span class="c1"># Vector representation of the fragment
</span>
</code></pre></div></div> <p>After we have all the embeddings, we create a list of Fragments and a Publication which we then store in the database using insertEmbeddings and insertPublication. These are simple wrappers on insert commands into the database.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">retreiveTextFromPdf</span><span class="p">(</span><span class="n">inp_file</span><span class="p">):</span>
    <span class="bp">...</span>
    <span class="n">fragments</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">txt</span><span class="p">,</span> <span class="n">embs</span> <span class="ow">in</span> <span class="n">txt_embs</span><span class="p">:</span>
        <span class="n">fragment</span> <span class="o">=</span> <span class="nc">Fragment</span><span class="p">(</span><span class="n">doi</span><span class="p">,</span> <span class="sh">'</span><span class="s">methods</span><span class="sh">'</span><span class="p">,</span> <span class="n">txt</span><span class="p">,</span> <span class="n">embs</span><span class="p">)</span>
        <span class="n">fragments</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">fragment</span><span class="p">)</span>

    <span class="n">publication</span> <span class="o">=</span> <span class="nc">Publication</span><span class="p">(</span><span class="n">doi</span><span class="p">,</span> <span class="n">title</span><span class="p">,</span> <span class="n">pmc</span><span class="p">,</span> <span class="n">pubmed</span><span class="p">,</span> <span class="n">doi</span><span class="p">)</span>

    <span class="n">lantern</span><span class="p">.</span><span class="nf">insertEmbeddings</span><span class="p">(</span><span class="n">fragments</span><span class="p">)</span>
    <span class="n">lantern</span><span class="p">.</span><span class="nf">insertPublication</span><span class="p">(</span><span class="n">publication</span><span class="p">)</span>

    <span class="n">os</span><span class="p">.</span><span class="nf">remove</span><span class="p">(</span><span class="n">pdfsavefile</span><span class="p">)</span>
</code></pre></div></div> <p>This code has the ability to be run automatically once a day through a script or with a fixed timespan if run manually.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="sh">"</span><span class="s">__main__</span><span class="sh">"</span><span class="p">:</span>
    <span class="c1"># Adding command line arguments for start_date and end_date with default values as the current date
</span>    <span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="p">.</span><span class="nc">ArgumentParser</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="sh">"</span><span class="s">Scrape and process scientific papers from bioRxiv.</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">parser</span><span class="p">.</span><span class="nf">add_argument</span><span class="p">(</span><span class="sh">"</span><span class="s">--start-date</span><span class="sh">"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="nf">str</span><span class="p">(</span><span class="n">datetime</span><span class="p">.</span><span class="n">date</span><span class="p">.</span><span class="nf">today</span><span class="p">()),</span> <span class="n">help</span><span class="o">=</span><span class="sh">"</span><span class="s">Start date for the scraping (format: </span><span class="sh">'</span><span class="s">YYYY-MM-DD</span><span class="sh">'</span><span class="s">).</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">parser</span><span class="p">.</span><span class="nf">add_argument</span><span class="p">(</span><span class="sh">"</span><span class="s">--end-date</span><span class="sh">"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="nf">str</span><span class="p">(</span><span class="n">datetime</span><span class="p">.</span><span class="n">date</span><span class="p">.</span><span class="nf">today</span><span class="p">()),</span> <span class="n">help</span><span class="o">=</span><span class="sh">"</span><span class="s">End date for the scraping (format: </span><span class="sh">'</span><span class="s">YYYY-MM-DD</span><span class="sh">'</span><span class="s">).</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">parser</span><span class="p">.</span><span class="nf">add_argument</span><span class="p">(</span><span class="sh">"</span><span class="s">--outfile</span><span class="sh">"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="sh">"</span><span class="s">bio.jsonl</span><span class="sh">"</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="sh">"</span><span class="s">Output file to save the metadata in JSON Lines format.</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="p">.</span><span class="nf">parse_args</span><span class="p">()</span>

    <span class="c1"># Calling the scrapeBiorxiv function with command line arguments
</span>    <span class="nf">scrapeBiorxiv</span><span class="p">(</span><span class="n">args</span><span class="p">.</span><span class="n">start_date</span><span class="p">,</span> <span class="n">args</span><span class="p">.</span><span class="n">end_date</span><span class="p">,</span> <span class="n">args</span><span class="p">.</span><span class="n">out_file</span><span class="p">)</span>
</code></pre></div></div> <p>The next part of the program is the document analyzer, which automates the evaluation of publications. This component of the system is designed to determine whether a paper mentions specific structural biology methods and subsequently updates the tracking systems with the results. The document analyzer is encapsulated in the DocumentAnalyzer class. It integrates with several services, including the Lantern vector database, Google Sheets for result tracking, and our custom LlmHandler class for handling interactions with the large language model (LLM).</p> <p>For every unread publication in the database, the text embeddings are retrieved to check if the paper is about cryo-EM, analyze the publication if it is, then update the spreadsheet with the results, and send an email notification if configured to do so.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="sh">"""</span><span class="s">
    pulls all new files from Lantern database, evaluates them, and publishes results to google sheets
    </span><span class="sh">"""</span>
    <span class="k">def</span> <span class="nf">analyze_all_unread</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">publications</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">lantern</span><span class="p">.</span><span class="nf">getUnreadPublications</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="nf">process_publications</span><span class="p">(</span><span class="n">publications</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">process_publications</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">publications</span><span class="p">:</span> <span class="p">[</span><span class="n">Publication</span><span class="p">]):</span>
        <span class="sh">"""</span><span class="s">takes a list of publications, applies retrievalQA and processes responses

        Args:
            publications ([]): list of publications 
        </span><span class="sh">"""</span>

        <span class="n">rows</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">hits</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">pub</span> <span class="ow">in</span> <span class="n">publications</span><span class="p">:</span>
            <span class="n">text_embeddings</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">lantern</span><span class="p">.</span><span class="nf">get_embeddings_for_pub</span><span class="p">(</span><span class="n">pub</span><span class="p">.</span><span class="nb">id</span><span class="p">)</span>
            <span class="n">classification</span><span class="p">,</span> <span class="n">response</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="sh">''</span>
            <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="nf">paper_about_cryoem</span><span class="p">(</span><span class="n">text_embeddings</span><span class="p">):</span>
                <span class="n">classification</span><span class="p">,</span> <span class="n">response</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">analyze_publication</span><span class="p">(</span><span class="n">text_embeddings</span><span class="p">)</span>
                <span class="n">hits</span> <span class="o">+=</span> <span class="n">classification</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># print('paper not about cryo-em')
</span>                <span class="k">pass</span>
            <span class="c1"># add date if it's added 
</span>            <span class="n">rows</span><span class="p">.</span><span class="nf">append</span><span class="p">([</span><span class="n">pub</span><span class="p">.</span><span class="n">doi</span><span class="p">,</span> <span class="n">pub</span><span class="p">.</span><span class="n">title</span><span class="p">,</span> <span class="sh">""</span><span class="p">,</span> <span class="nf">str</span><span class="p">(</span><span class="n">date</span><span class="p">.</span><span class="nf">today</span><span class="p">()),</span> <span class="sh">""</span><span class="p">,</span> <span class="nf">int</span><span class="p">(</span><span class="n">classification</span><span class="p">),</span> <span class="n">response</span><span class="p">,</span> <span class="sh">""</span><span class="p">])</span>

        <span class="n">self</span><span class="p">.</span><span class="nf">update_spreadsheet</span><span class="p">(</span><span class="n">rows</span><span class="p">,</span> <span class="n">hits</span><span class="p">)</span>
</code></pre></div></div> <p>We know its unread since we used a separate table that only contains the id of publications that were inserted after the last read.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="sh">"""</span><span class="s">
    Retrieves unread publications from the </span><span class="sh">'</span><span class="s">publications</span><span class="sh">'</span><span class="s"> table.
    Parameters:
        - delete_unread_entries: bool, decides if entries are deleted from the </span><span class="sh">"</span><span class="s">unread</span><span class="sh">"</span><span class="s"> table
    Returns:
        - List[Publication], a list of Publication objects representing the unread publications.
    Notes:
        - Performs a left join between </span><span class="sh">'</span><span class="s">publications</span><span class="sh">'</span><span class="s"> and </span><span class="sh">'</span><span class="s">unread</span><span class="sh">'</span><span class="s"> tables to retrieve unread publications.
        - Clears the </span><span class="sh">'</span><span class="s">unread</span><span class="sh">'</span><span class="s"> table after retrieving the unread publications.
    </span><span class="sh">"""</span>

    <span class="k">def</span> <span class="nf">getUnreadPublications</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">delete_unread_entries</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
        <span class="n">conn</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">conn</span>
        <span class="n">cursor</span> <span class="o">=</span> <span class="n">conn</span><span class="p">.</span><span class="nf">cursor</span><span class="p">()</span>

        <span class="n">cursor</span><span class="p">.</span><span class="nf">execute</span><span class="p">(</span>
            <span class="sh">'</span><span class="s">SELECT * FROM publications AS p LEFT JOIN unread AS u ON u.id=p.id;</span><span class="sh">'</span><span class="p">)</span>

        <span class="n">publications</span> <span class="o">=</span> <span class="n">cursor</span><span class="p">.</span><span class="nf">fetchall</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">delete_unread_entries</span><span class="p">:</span>
            <span class="n">cursor</span><span class="p">.</span><span class="nf">execute</span><span class="p">(</span><span class="sh">'</span><span class="s">DELETE FROM unread;</span><span class="sh">'</span><span class="p">)</span>

        <span class="n">conn</span><span class="p">.</span><span class="nf">commit</span><span class="p">()</span>
        <span class="n">cursor</span><span class="p">.</span><span class="nf">close</span><span class="p">()</span>

        <span class="n">publicationObjects</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">publications</span><span class="p">:</span>
            <span class="n">publicationObjects</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span>
                <span class="nc">Publication</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">p</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">p</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">p</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">p</span><span class="p">[</span><span class="mi">4</span><span class="p">]))</span>

        <span class="k">return</span> <span class="n">publicationObjects</span>
</code></pre></div></div> <p>However, in retrospect, it might make more sense to just have an additional column in the publications table as to whether its unread.</p> <p>The analyze_publications function analyzes a publication to determine if it mentions any structural biology methods. It uses FAISS for embedding-based retrieval and the LLM for query evaluation.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">def</span> <span class="nf">analyze_publication</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">text_embeddings</span><span class="p">:</span> <span class="p">[]):</span>
        <span class="sh">"""</span><span class="s">poses a question about the document, processes the result and returns it
        NOTE: for now, only uses the hackathon question, might add more later

        Args:
            text_embeddings ([]): list of (embedding, text) pairs from document to be analyzed
        
        Returns:
            bool: classification of response to query as positive (True) or negative (False) 
            str: response from chatGPT
        </span><span class="sh">"""</span>
        <span class="c1"># NOTE: These very likely need to change
</span>        <span class="n">open_ai_emb</span> <span class="o">=</span> <span class="nc">OpenAIEmbeddings</span><span class="p">()</span>
        <span class="n">query</span> <span class="o">=</span> <span class="nf">get_qbi_hackathon_prompt</span><span class="p">(</span><span class="n">METHODS_KEYWORDS</span><span class="p">)</span>
        <span class="n">faiss_index</span> <span class="o">=</span> <span class="n">FAISS</span><span class="p">.</span><span class="nf">from_embeddings</span><span class="p">(</span><span class="n">text_embeddings</span><span class="o">=</span><span class="n">text_embeddings</span><span class="p">,</span> <span class="n">embedding</span><span class="o">=</span><span class="n">open_ai_emb</span><span class="p">)</span>
        <span class="n">response</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">llm</span><span class="p">.</span><span class="nf">evaluate_queries</span><span class="p">(</span><span class="n">faiss_index</span><span class="p">,</span> <span class="n">query</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">classify_response</span><span class="p">(</span><span class="n">response</span><span class="p">),</span> <span class="n">response</span>
</code></pre></div></div> <p>We utilized several keywords to assist the LLM in identifing certain methodologies. We used the get_qbi_hackathon_prompt function to format our prompt using the keywords. They can be seen below as a guide:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="c1"># A list of abbreviated names and synonyms
# for various biophysical methonds
# that are typically used for integrative modeling
</span>
<span class="n">METHODS_KEYWORDS</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">'</span><span class="s">CX-MS</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span>
        <span class="sh">'</span><span class="s">cross-link</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">crosslink</span><span class="sh">'</span><span class="p">,</span>
        <span class="sh">'</span><span class="s">XL-MS</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">CX-MS</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">CL-MS</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">XLMS</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">CXMS</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">CLMS</span><span class="sh">'</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">chemical crosslinking mass spectrometry</span><span class="sh">"</span><span class="p">,</span>
        <span class="sh">'</span><span class="s">photo-crosslinking</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">crosslinking restraints</span><span class="sh">'</span><span class="p">,</span>
        <span class="sh">'</span><span class="s">crosslinking-derived restraints</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">chemical crosslinking</span><span class="sh">'</span><span class="p">,</span>
        <span class="sh">'</span><span class="s">in vivo crosslinking</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">crosslinking data</span><span class="sh">'</span><span class="p">,</span>
    <span class="p">],</span>

    <span class="sh">'</span><span class="s">HDX</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span>
        <span class="sh">'</span><span class="s">Hydrogen–deuterium exchange mass spectrometry</span><span class="sh">'</span><span class="p">,</span>
        <span class="sh">'</span><span class="s">Hydrogen/deuterium exchange mass spectrometry</span><span class="sh">'</span>
        <span class="sh">'</span><span class="s">HDX</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">HDXMS</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">HDX-MS</span><span class="sh">'</span><span class="p">,</span>
    <span class="p">],</span>

    <span class="sh">'</span><span class="s">EPR</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span>
        <span class="sh">'</span><span class="s">electron paramagnetic resonance spectroscopy</span><span class="sh">'</span><span class="p">,</span>
        <span class="sh">'</span><span class="s">EPR</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">DEER</span><span class="sh">'</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">Double electron electron resonance spectroscopy</span><span class="sh">"</span><span class="p">,</span>
    <span class="p">],</span>

    <span class="sh">'</span><span class="s">FRET</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span>
        <span class="sh">'</span><span class="s">FRET</span><span class="sh">'</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">forster resonance energy transfer</span><span class="sh">"</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">fluorescence resonance energy transfer</span><span class="sh">"</span><span class="p">,</span>
    <span class="p">],</span>

    <span class="sh">'</span><span class="s">AFM</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span>
        <span class="sh">'</span><span class="s">AFM</span><span class="sh">'</span><span class="p">,</span>  <span class="sh">"</span><span class="s">atomic force microscopy</span><span class="sh">"</span><span class="p">,</span>
    <span class="p">],</span>

    <span class="sh">'</span><span class="s">SAS</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span>
        <span class="sh">'</span><span class="s">SAS</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">SAXS</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">SANS</span><span class="sh">'</span><span class="p">,</span> <span class="sh">"</span><span class="s">Small angle solution scattering</span><span class="sh">"</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">solution scattering</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">SEC-SAXS</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">SEC-SAS</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">SASBDB</span><span class="sh">"</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">Small angle X-ray scattering</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Small angle neutron scattering</span><span class="sh">"</span><span class="p">,</span>
    <span class="p">],</span>

    <span class="sh">'</span><span class="s">3DGENOME</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span>
        <span class="sh">'</span><span class="s">HiC</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Hi-C</span><span class="sh">'</span><span class="p">,</span> <span class="sh">"</span><span class="s">chromosome conformation capture</span><span class="sh">"</span><span class="p">,</span>
    <span class="p">],</span>

    <span class="sh">'</span><span class="s">Y2H</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span>
        <span class="sh">'</span><span class="s">Y2H</span><span class="sh">'</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">yeast two-hybrid</span><span class="sh">"</span><span class="p">,</span>
    <span class="p">],</span>

    <span class="sh">'</span><span class="s">DNA_FOOTPRINTING</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span>
        <span class="sh">"</span><span class="s">DNA Footprinting</span><span class="sh">"</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">hydroxyl radical footprinting</span><span class="sh">"</span><span class="p">,</span>
    <span class="p">],</span>

    <span class="sh">'</span><span class="s">XRAY_TOMOGRAPHY</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span>
        <span class="sh">"</span><span class="s">soft x-ray tomography</span><span class="sh">"</span><span class="p">,</span>
    <span class="p">],</span>

    <span class="sh">'</span><span class="s">FTIR</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span>
        <span class="sh">"</span><span class="s">FTIR</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Infrared spectroscopy</span><span class="sh">"</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">Fourier-transform infrared spectroscopy</span><span class="sh">"</span><span class="p">,</span>
    <span class="p">],</span>

    <span class="sh">'</span><span class="s">FLUORESCENCE</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span>
        <span class="sh">"</span><span class="s">Fluorescence imaging</span><span class="sh">"</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">fluorescence microscopy</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">TIRF</span><span class="sh">"</span><span class="p">,</span>
    <span class="p">],</span>

    <span class="sh">'</span><span class="s">EVOLUTION</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span>
        <span class="sh">'</span><span class="s">coevolution</span><span class="sh">'</span><span class="p">,</span> <span class="sh">"</span><span class="s">evolutionary covariance</span><span class="sh">"</span><span class="p">,</span>
    <span class="p">],</span>

    <span class="sh">'</span><span class="s">PREDICTED</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span>
        <span class="sh">"</span><span class="s">predicted contacts</span><span class="sh">"</span><span class="p">,</span>
    <span class="p">],</span>

    <span class="sh">'</span><span class="s">INTEGRATIVE</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span>
        <span class="sh">"</span><span class="s">integrative structure</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">hybrid structure</span><span class="sh">"</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">integrative modeling</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">hybrid modeling</span><span class="sh">"</span><span class="p">,</span>
    <span class="p">],</span>

    <span class="sh">'</span><span class="s">SHAPE</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span>
        <span class="sh">'</span><span class="s">Hydroxyl Acylation analyzed by Primer Extension</span><span class="sh">'</span><span class="p">,</span>
    <span class="p">]</span>
<span class="p">}</span>

<span class="k">def</span> <span class="nf">get_qbi_hackathon_prompt</span><span class="p">(</span><span class="n">keywords</span><span class="p">:</span> <span class="nb">dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Returns a prompt that was initially developed
    during the QBI Hackathon.
    </span><span class="sh">"""</span>

    <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">keywords</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nf">raise</span><span class="p">(</span><span class="nc">ValueError</span><span class="p">(</span><span class="sh">"</span><span class="s">Keywords dict can</span><span class="sh">'</span><span class="s">t be empty</span><span class="sh">"</span><span class="p">))</span>

    <span class="n">methods_string</span> <span class="o">=</span> <span class="nf">keywords_dict_to_string</span><span class="p">(</span><span class="n">keywords</span><span class="p">)</span>

    <span class="n">prompt</span> <span class="o">=</span> <span class="p">(</span>
        <span class="sh">"</span><span class="s">You are reading a materials and methods section </span><span class="sh">"</span>
        <span class="sh">"</span><span class="s">of a scientific paper. </span><span class="sh">"</span>
        <span class="sa">f</span><span class="sh">"</span><span class="s">Here is the list of methods </span><span class="si">{</span><span class="n">methods_string</span><span class="si">}</span><span class="s">.</span><span class="se">\n\n</span><span class="sh">"</span>
        <span class="sh">"</span><span class="s">Did the authors use any of them? </span><span class="sh">"</span>
        <span class="sh">"</span><span class="s">Answer Yes or No, followed by the name(s) of methods. </span><span class="sh">"</span>
        <span class="sh">"</span><span class="s">Use only abbreviations.</span><span class="sh">"</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">prompt</span>
</code></pre></div></div> <p>We were also able to ask questions directly about the papers using the evaluate_queries method. We utilized the RetrievalQA capability in Langchain to provide retrieval augmentation for the response generation.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="k">def</span> <span class="nf">evaluate_queries</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">embedding</span><span class="p">,</span> <span class="n">queries</span><span class="p">):</span>
        <span class="n">chatbot</span> <span class="o">=</span> <span class="n">RetrievalQA</span><span class="p">.</span><span class="nf">from_chain_type</span><span class="p">(</span>
            <span class="n">llm</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">llm</span><span class="p">,</span> 
            <span class="n">chain_type</span><span class="o">=</span><span class="sh">"</span><span class="s">stuff</span><span class="sh">"</span><span class="p">,</span> 
            <span class="n">retriever</span><span class="o">=</span><span class="n">embedding</span><span class="p">.</span><span class="nf">as_retriever</span><span class="p">(</span><span class="n">search_type</span><span class="o">=</span><span class="sh">"</span><span class="s">similarity</span><span class="sh">"</span><span class="p">,</span> <span class="n">search_kwargs</span><span class="o">=</span><span class="p">{</span><span class="sh">"</span><span class="s">k</span><span class="sh">"</span><span class="p">:</span><span class="mi">3</span><span class="p">})</span>
        <span class="p">)</span>
        
        <span class="n">template</span> <span class="o">=</span> <span class="sh">"""</span><span class="s"> {query}? </span><span class="sh">"""</span>
        <span class="n">response</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">q</span> <span class="ow">in</span> <span class="n">queries</span><span class="p">:</span>
            <span class="n">prompt</span> <span class="o">=</span> <span class="nc">PromptTemplate</span><span class="p">(</span>
                <span class="n">input_variables</span><span class="o">=</span><span class="p">[</span><span class="sh">"</span><span class="s">query</span><span class="sh">"</span><span class="p">],</span>
                <span class="n">template</span><span class="o">=</span><span class="n">template</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">response</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">chatbot</span><span class="p">.</span><span class="nf">run</span><span class="p">(</span>
                <span class="n">prompt</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">query</span><span class="o">=</span><span class="n">q</span><span class="p">)</span>
            <span class="p">))</span>
        <span class="k">return</span> <span class="n">response</span>
</code></pre></div></div> <h2 id="results">Results</h2> <p>The results after completing the project were quite successful. Due to the nature of LLMs, we know that we need to test the accuracy to see if it is a useful tool. Using GPT 4.0, the developed system had an accuracy of .82 plus or minus 0.02 on a 95% confidence interval. Out of 20 runs, it got 17 correct, and provided two false positives and one false negative. This was more successful than GPT 3.5 which had a lower accuracy.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/QBIHackathon/Results-A-480.webp 480w,/assets/img/QBIHackathon/Results-A-800.webp 800w,/assets/img/QBIHackathon/Results-A-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/QBIHackathon/Results-A.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>The system filled out a spreadsheet with information about the papers including the methods and technologies used and provided updates through email.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/QBIHackathon/Results-B-480.webp 480w,/assets/img/QBIHackathon/Results-B-800.webp 800w,/assets/img/QBIHackathon/Results-B-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/QBIHackathon/Results-B.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>This project was a very fun hackathon project to work on and our team ended up winning first place!</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/QBIHackathon/Award-480.webp 480w,/assets/img/QBIHackathon/Award-800.webp 800w,/assets/img/QBIHackathon/Award-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/QBIHackathon/Award.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/QBIHackathon/Team-480.webp 480w,/assets/img/QBIHackathon/Team-800.webp 800w,/assets/img/QBIHackathon/Team-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/QBIHackathon/Team.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h2 id="key-takeaways">Key Takeaways</h2> <p>There were several key takeaways from this event.</p> <h3 id="structuring-a-project-based-on-requirements">Structuring a Project Based on Requirements</h3> <p>One of the most critical aspects of this hackathon was learning how to structure a project effectively to meet specific requirements.</p> <ol> <li>Requirement Analysis: Understanding the core problem of data scarcity in the Protein Data Bank and how to address it with automation.</li> <li>Clear Objectives: Defining clear goals such as automating the data extraction and annotation process, ensuring metadata accuracy, and facilitating integration with existing databases.</li> <li>Modular Design: Breaking down the project into manageable components like the bioRxiv scraper, document analyzer, and database management. This modular approach ensured that each part could be developed, tested, and integrated independently.</li> </ol> <h3 id="quick-delegation-and-integration-of-separate-work">Quick Delegation and Integration of Separate Work</h3> <p>Effective teamwork was another major takeaway.</p> <ol> <li>Role Assignment: Team members were assigned roles based on their expertise. For instance, some focused on backend development (like database management), others on the AI/ML components (like embeddings and LLM interaction), and others on integration and deployment.</li> <li>Regular Sync-Ups: The team held frequent check-ins to ensure everyone was on the same page, discuss progress, and troubleshoot any issues collaboratively.</li> <li>Integration Strategy: A clear integration plan was established early on. This involved setting up version control (e.g., using Git) and defining API contracts between different modules to ensure smooth integration.</li> </ol> <h3 id="working-with-llm-technologies">Working with LLM Technologies</h3> <p>The hackathon provided hands-on experience with various LLM technologies and tools.</p> <ol> <li>Vector Embeddings: Understanding how to convert text into vector embeddings using OpenAI’s embeddings and storing them in a vector database like Lantern Vector+postgres. This step was crucial for efficient retrieval and querying.</li> <li>FAISS Context Retrieval: Learning how to use FAISS for context retrieval based on cosine similarity. This involved setting up FAISS and using it to fetch relevant document fragments.</li> <li>Langchain for LLM Utilities: Utilizing Langchain to handle various LLM utilities, making the interaction with the GPT-4.0 API more seamless and efficient.</li> <li>Automating Data Annotation: Developing scripts that leverage GPT-4.0 to automate the process of annotating scientific papers, extracting relevant metadata, and updating databases.</li> </ol> <p>The repository with all of the code can be found below:</p> <div class="repositories d-flex flex-wrap flex-md-row flex-column justify-content-between align-items-center"> <div class="repo p-2 text-center"> <a href="https://github.com/aozalevsky/structhunt" rel="external nofollow noopener" target="_blank"> <img class="repo-img-light w-100" alt="aozalevsky/structhunt" src="https://github-readme-stats.vercel.app/api/pin/?username=aozalevsky&amp;repo=structhunt&amp;theme=default&amp;show_owner=true&amp;description_lines_count=1"> <img class="repo-img-dark w-100" alt="aozalevsky/structhunt" src="https://github-readme-stats.vercel.app/api/pin/?username=aozalevsky&amp;repo=structhunt&amp;theme=dark&amp;show_owner=true&amp;description_lines_count=1"> </a> </div> </div> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/JuliaSetVisualizer/">Julia Set Visualization</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/Crowdstrike/">Crowdstrike - A Reflection</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/Private-Pilot/">My Journey to Become a Private Pilot</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2022/Druid-Heights/">Druid Heights</a> </li> <div id="giscus_thread" style="max-width: 930px; margin: 0 auto;"> <script>let giscusTheme=determineComputedTheme(),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"Alexander-Aghili/website","data-repo-id":"R_kgDOMQoMew","data-category":"Comments","data-category-id":"DIC_kwDOMQoMe84CgkDQ","data-mapping":"pathname","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,e])=>giscusScript.setAttribute(t,e)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Alexander Aghili. Last updated: October 05, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-W1QMCLW1DQ"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-W1QMCLW1DQ");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-projects",title:"projects",description:"",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-repositories",title:"repositories",description:"",section:"Navigation",handler:()=>{window.location.href="/repositories/"}},{id:"nav-cv",title:"cv",description:"",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"post-julia-set-visualization",title:"Julia Set Visualization",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/JuliaSetVisualizer/"}},{id:"post-the-bio-science-ai-hackathon",title:"The Bio-Science AI Hackathon",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/QBI-Hackthon/"}},{id:"post-crowdstrike-a-reflection",title:"Crowdstrike - A Reflection",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/Crowdstrike/"}},{id:"post-my-journey-to-become-a-private-pilot",title:"My Journey to Become a Private Pilot",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/Private-Pilot/"}},{id:"post-druid-heights",title:"Druid Heights",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2022/Druid-Heights/"}},{id:"news-a-simple-inline-announcement-with-markdown-emoji-sparkles-smile",title:'A simple inline announcement with Markdown emoji! <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20">',description:"",section:"News"},{id:"news-a-long-announcement-with-details",title:"A long announcement with details",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_2/"}},{id:"news-a-simple-inline-announcement",title:"A simple inline announcement.",description:"",section:"News"},{id:"projects-public-poll-mobile-app",title:"Public Poll Mobile App",description:"This is a mobile app that I developed to use as polls between my friends",section:"Projects",handler:()=>{window.location.href="/projects/2022-09-21-Public-Poll-Mobile-App/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%61%6C%65%78%61%6E%64%65%72.%77.%61%67%68%69%6C%69@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/Alexander-Aghili","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/AlexanderAghili","_blank")}},{id:"socials-x",title:"X",description:"Twitter",section:"Socials",handler:()=>{window.open("https://twitter.com/AghiliAlexander","_blank")}},{id:"socials-discord",title:"Discord",section:"Socials",handler:()=>{window.open("https://discord.com/users/379156584275640320","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js"></script> </body> </html>